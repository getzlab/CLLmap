{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:54:22.158100Z",
     "start_time": "2021-04-22T21:54:22.155387Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas\n",
    "from imblearn.over_sampling import SMOTE, ADASYN, SVMSMOTE, BorderlineSMOTE\n",
    "import sklearn\n",
    "import seaborn\n",
    "import argparse\n",
    "import pickle\n",
    "import sklearn\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Argument Parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:05.588252Z",
     "start_time": "2021-04-22T21:52:05.585060Z"
    }
   },
   "outputs": [],
   "source": [
    "def pArgs(args):\n",
    "    output = argparse.ArgumentParser('Run predictor for specific data on cll data.')\n",
    "\n",
    "    output.add_argument('data', type=str, help='Path to data file.')\n",
    "    output.add_argument('labels', type=str, help='Path to label file.')\n",
    "    output.add_argument('--full_data', type=str, help='Path to full dataset to make predictions.', default=None)\n",
    "    output.add_argument('--save-path', type=str, help='Path to save plots.', default=None)\n",
    "    output.add_argument('--crossvalidate', type=int, help='Number of crossvalidation folds for metrics. 0 for no crossvalidation.', default=5)\n",
    "    output.add_argument('--verbose', action='store_true', help='Show status of analysis.')\n",
    "\n",
    "    return output.parse_args(args[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Core crossvalidation function\n",
    "This function loads data and iterates over the oversamples and does the splitted training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:53.393297Z",
     "start_time": "2021-04-22T21:52:53.384064Z"
    }
   },
   "outputs": [],
   "source": [
    "def load(path_x, path_y, split=0.15, seed=0):\n",
    "    x = pandas.read_csv(path_x, index_col=0)\n",
    "    y = pandas.read_csv(path_y, index_col=0)\n",
    "\n",
    "    if split == 0:\n",
    "        return x, y\n",
    "    else:\n",
    "        return train_test_split(x, y, test_size=0.15, random_state=seed)\n",
    "    \n",
    "def run_cross(args, target_func, name, split=0.15, seed=0, scaler_class=sklearn.preprocessing.StandardScaler, save_path=None, **kwargs_func):\n",
    "    data_original, labels_original = load(args.data, args.labels, split=0)\n",
    "\n",
    "    res = list()\n",
    "\n",
    "    for overs in [\"\", \"SMOTE\", \"ADASYN\", \"SVMSMOTE\", \"BorderlineSMOTE\"]:\n",
    "        print('Oversampling: ', overs)\n",
    "        try:\n",
    "            temp = train_cv(args, data_original, labels_original, target_func, overs, n_splits=args.crossvalidate)\n",
    "            res.append( (overs + ' Raw ' + name, *temp) )\n",
    "            if args.verbose:\n",
    "                print('raw done')\n",
    "        except:\n",
    "            raise\n",
    "\n",
    "        try:\n",
    "            temp = train_cv(args, data_original, labels_original, target_func, overs, n_splits=args.crossvalidate, scaler=scaler_class())\n",
    "            res.append( (overs + ' Scaled ' + name, *temp) )\n",
    "            if args.verbose:\n",
    "                print('raw done')\n",
    "        except:\n",
    "            raise\n",
    "\n",
    "    try:\n",
    "        best = sorted(res, key=lambda x: x[1][0], reverse=True)[0]\n",
    "        draw(path=args.save_path + '/plots/' + name + '_' + str(best[2][0]) if args.save_path is not None else None, arguments=args, *res)\n",
    "        print('Best:', best[0], best[1][0])\n",
    "    except:\n",
    "        print('No data')\n",
    "        raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plotting\n",
    "Given the output of a crossvalidating training set plot the resulting confusion matrix and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:05.605704Z",
     "start_time": "2021-04-22T21:52:05.597754Z"
    }
   },
   "outputs": [],
   "source": [
    "def draw(*args, path=None, arguments=None):\n",
    "    n = int(numpy.ceil(numpy.sqrt(len(args))))\n",
    "    f, ax = plt.subplots(int(numpy.ceil(len(args)/n)), n)\n",
    "    f.set_size_inches(16,9)\n",
    "    f.set_dpi(500)\n",
    "    assert(len(args) <= n*numpy.ceil(len(args)/n))\n",
    "\n",
    "    ax = ax.flatten()\n",
    "    \n",
    "    for i in range(len(args)):\n",
    "        confus1 = args[i][1] if arguments is None or arguments.crossvalidate == 0 else args[i][1][-2] \n",
    "        confus = args[i][1] if arguments is None or arguments.crossvalidate == 0 else args[i][1][-2] \n",
    "        confus = numpy.nan_to_num(confus / confus.sum(axis=0))\n",
    "        seaborn.heatmap(confus, vmax=1.0, xticklabels=range(1, confus.shape[0]+1), yticklabels=range(1, confus.shape[0]+1), cmap='YlOrRd', ax=ax[i], annot=confus1, fmt='d', square=True)\n",
    "        if arguments is None or arguments.crossvalidate == 0:\n",
    "            ax[i].set_title(args[i][0] + '\\nAccuracy: ' + str(args[i][2]) + ' - Recall:' + str(args[i][3]) + ' - F1: ' + str(args[i][4]))\n",
    "        else:\n",
    "            ax[i].set_title(args[i][0] + '\\nAccuracy: ' + str(args[i][1][0]) + ' - Recall:' + str(args[i][1][1]) + ' - F1: ' + str(args[i][1][2]) + '\\nAccuracy: ' + str(args[i][2][0]) + '+/-' + str(args[i][2][1]) + '\\nRecall: ' + str(args[i][3][0]) + '+/-' + str(args[i][3][1]) + '\\nF1: ' + str(args[i][3][0]) + '+/-' + str(args[i][3][1]))\n",
    "            \n",
    "        ax[i].set_ylabel('Real')\n",
    "        ax[i].set_xlabel('Predicted')\n",
    "\n",
    "    f.set_tight_layout(True)\n",
    "    plt.tight_layout()\n",
    "    if path is not None:\n",
    "        plt.savefig(path + '_plot.pdf')\n",
    "    else:\n",
    "        plt.show()\n",
    "        \n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train function\n",
    "This functions manages the crossvalidation splits for a given set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:05.623234Z",
     "start_time": "2021-04-22T21:52:05.606664Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_cv(args, X, Y, target_f, oversampler, n_splits=10, scaler=None):\n",
    "    cv = sklearn.model_selection.StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=0)\n",
    "    res = list()\n",
    "    \n",
    "    for i, (train1, test1) in enumerate(cv.split(X, Y)):\n",
    "        x_train = X.iloc[train1]\n",
    "        y_train = Y.iloc[train1]\n",
    "        x_test = X.iloc[test1]\n",
    "        y_test = Y.iloc[test1]\n",
    "        \n",
    "        if scaler is not None:\n",
    "            if x_train.columns.str.contains('vsAll').any():\n",
    "                c = x_train.columns.str.contains('vsAll')\n",
    "                x_train[x_train.columns[c]] = x_train[x_train.columns[c]].div(x_train[x_train.columns[c]].sum(axis=1), axis=0) * 1000000\n",
    "                x_test[x_test.columns[c]] = x_test[x_test.columns[c]].div(x_test[x_test.columns[c]].sum(axis=1), axis=0) * 1000000\n",
    "                \n",
    "                x_train[x_train.columns[~c]] = x_train[x_train.columns[~c]].div(x_train[x_train.columns[~c]].sum(axis=1), axis=0) * 1000000\n",
    "                x_test[x_test.columns[~c]] = x_test[x_test.columns[~c]].div(x_test[x_test.columns[~c]].sum(axis=1), axis=0) * 1000000\n",
    "                \n",
    "            else:\n",
    "                x_train = x_train.div(x_train.sum(axis=1), axis=0) * 1000000\n",
    "                x_test = x_test.div(x_test.sum(axis=1), axis=0) * 1000000\n",
    "            \n",
    "        pred, model = train(x_train, y_train, x_test, y_test, target_f, oversampler=oversampler)\n",
    "\n",
    "        full = pandas.read_csv(args.full_data, index_col=0).T\n",
    "        full = full[x_train.columns]\n",
    "        \n",
    "        if scaler is not None:\n",
    "            if full.columns.str.contains('vsAll').any():\n",
    "                c = full.columns.str.contains('vsAll')\n",
    "                full[full.columns[c]] = full[full.columns[c]].div(full[full.columns[c]].sum(axis=1), axis=0) * 1000000\n",
    "                \n",
    "                full[full.columns[~c]] = full[full.columns[~c]].div(full[full.columns[~c]].sum(axis=1), axis=0) * 1000000\n",
    "                \n",
    "            else:\n",
    "                full = full.div(full.sum(axis=1), axis=0) * 1000000\n",
    "        \n",
    "        res2 = pandas.DataFrame(model.predict_proba(full))\n",
    "        res2.index = full.index\n",
    "        res2.columns = ['Cluster {}'.format(i) for i in range(len(res2.columns))]\n",
    "        res2['Pred_Cluster'] = model.predict(full)\n",
    "        \n",
    "        \n",
    "        if scaler is not None and False:\n",
    "            model = sklearn.pipeline.Pipeline([('scaler', scaler), ('model', model)])\n",
    "        \n",
    "        confus = sklearn.metrics.confusion_matrix(y_test, pred)\n",
    "        acc = int(sklearn.metrics.accuracy_score(y_test, pred) * 1000) / 1000\n",
    "        recall = int(sklearn.metrics.recall_score(y_test, pred, average='micro') * 1000) / 1000\n",
    "        f1 = int(sklearn.metrics.f1_score(y_test, pred, average='micro' ) * 1000) / 1000\n",
    "        \n",
    "        res.append( (acc, recall, f1, confus, model) )\n",
    "        name = target_f.__name__ + '_' + oversampler + '_split_' + str(i)\n",
    "        if scaler is not None:\n",
    "            name = name + '_scaled'\n",
    "        if oversampler != '' and oversampler is not None:\n",
    "            name = name + '_' + oversampler\n",
    "            \n",
    "        res2.to_csv(args.save_path + '/' + name + '_full_predict_fold_' + str(i) + '.csv')\n",
    "            \n",
    "        save_soft_clustering_predictions_split(args, model, name, X, Y, train1, test1, acc) \n",
    "        with open(args.save_path + '/models/' + name + '_' + str(acc) + '.pickle', 'wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "        \n",
    "    plt.clf()\n",
    "    plt.plot(range(len(res)), [x[0] for x in res])\n",
    "    plt.xlabel('Fold #')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Fold accuracy for {}'.format(target_f.__name__))\n",
    "    name = args.save_path + '/plots/fold_accs_' + target_f.__name__\n",
    "    if oversampler is not None:\n",
    "        name = name + '_' + oversampler\n",
    "        \n",
    "    if scaler is not None:\n",
    "        name = name + '_scaled'\n",
    "    plt.savefig(name) \n",
    "    \n",
    "    res = sorted(res, key=lambda x: x[0], reverse=True)\n",
    "    best = res[0]\n",
    "    \n",
    "    acc_m = numpy.format_float_positional(numpy.mean([x[0] for x in res]), precision=2, unique=False, fractional=False, trim='k')\n",
    "    acc_s = numpy.format_float_positional(numpy.std([x[0] for x in res]), precision=2, unique=False, fractional=False, trim='k')\n",
    "    \n",
    "    rec_m = numpy.format_float_positional(numpy.mean([x[1] for x in res]), precision=2, unique=False, fractional=False, trim='k')\n",
    "    rec_s = numpy.format_float_positional(numpy.std([x[1] for x in res]), precision=2, unique=False, fractional=False, trim='k')\n",
    "    \n",
    "    f1_m = numpy.format_float_positional(numpy.mean([x[2] for x in res]), precision=2, unique=False, fractional=False, trim='k')\n",
    "    f1_s = numpy.format_float_positional(numpy.std([x[2] for x in res]), precision=2, unique=False, fractional=False, trim='k')\n",
    "    \n",
    "    return best, (acc_m, acc_s), (rec_m, rec_s), (f1_m, f1_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "Deals with routing the data to the actual training function and returns results and trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:05.635487Z",
     "start_time": "2021-04-22T21:52:05.624151Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(x, y, xt, yt, target_function, oversampler=None, pandas_column='bnmf_expression_cluster', **f_kwargs):\n",
    "    oversamplers = {\"SMOTE\":SMOTE, \"ADASYN\":ADASYN, \"SVMSMOTE\":SVMSMOTE, \"BorderlineSMOTE\":BorderlineSMOTE}\n",
    "    x1, y1 = x, y\n",
    "    try:\n",
    "        if oversampler is not None and oversampler != \"\":\n",
    "            if pandas_column != None:\n",
    "                x1, y1 = oversamplers[oversampler](random_state=0).fit_resample(x1, y1[pandas_column])\n",
    "            else:\n",
    "                x1, y1 = oversamplers[oversampler](random_state=0).fit_resample(x1, y1)\n",
    "                \n",
    "            x1 = x1.sample(frac=1)\n",
    "            y1 = y1.iloc[x1.index]\n",
    "    except:\n",
    "        print('no samples generated extra')\n",
    "        \n",
    "    return target_function(x1, y1, xt, yt, **f_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Plots\n",
    "For a full dataset and a trained model calculate all scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:05.643902Z",
     "start_time": "2021-04-22T21:52:05.637509Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_soft_clustering_predictions_split(args, model, name, data, labels, split_train, split_test, acc):\n",
    "    def f(x):\n",
    "        return -x.sort_values(inplace=False, ascending=False)[:2].diff()[1]\n",
    "        \n",
    "    df = model.predict_proba(data)\n",
    "    df = pandas.DataFrame(df)\n",
    "    df.columns = ['cluster_' + str(i) for i in model.classes_]\n",
    "    df['diff_top2'] = df.apply(f, axis=1)\n",
    "    \n",
    "    df['pred'] = model.predict(data)\n",
    "    \n",
    "    df.index = data.index\n",
    "    df.index.name = 'sample_id'\n",
    "    df['real_cluster'] = labels\n",
    "    is_test = numpy.zeros(df.shape[0])\n",
    "    is_test[split_test] = 1\n",
    "    \n",
    "    df['test_sample'] = is_test\n",
    "    \n",
    "    df.to_csv(args.save_path + '/soft_clust/' + name + '_' + str(acc) + '.csv')\n",
    "    \n",
    "    plt.clf()\n",
    "    df['yis'] = (df['real_cluster'] == df['pred']).astype('int')\n",
    "    df.groupby('yis').boxplot(column=['diff_top2'])\n",
    "    plt.savefig(args.save_path + '/plots/box_diff_' + name + '_' + str(acc) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "This actually instances the models and deals with the __fit()__ function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:05.651953Z",
     "start_time": "2021-04-22T21:52:05.645187Z"
    }
   },
   "outputs": [],
   "source": [
    "def rf2(x, y, xt, yt, estimators=1000):\n",
    "    y1 = to_categorical(y)\n",
    "    yt1 = to_categorical(yt)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = estimators, random_state = 236, class_weight='balanced_subsample')\n",
    "\n",
    "    rf.fit(x, y.to_numpy().ravel())\n",
    "\n",
    "    y_pred = rf.predict(xt)\n",
    "\n",
    "    return y_pred, rf\n",
    "\n",
    "def rf(x, y, xt, yt, estimators=500):\n",
    "    y1 = to_categorical(y)\n",
    "    yt1 = to_categorical(yt)\n",
    "\n",
    "    rf = RandomForestClassifier(n_estimators = estimators, random_state = 236, class_weight='balanced_subsample')\n",
    "\n",
    "    rf.fit(x, y.to_numpy())    \n",
    "    \n",
    "    y_pred = rf.predict(xt)\n",
    "\n",
    "    return y_pred, rf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing dataset\n",
    "This selects samples and genes + genesets for the pipeline.  \n",
    "This is not a part of the notebook but added for storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:52:05.660136Z",
     "start_time": "2021-04-22T21:52:05.653262Z"
    }
   },
   "outputs": [],
   "source": [
    "#Input: Full TPM/counts matrix\n",
    "#Output: Subsets to genes and samples of interest (used in this notebook)\n",
    "def parse_dataset(data_path, geneset_list_path, samples_path, labels_path, genes_path):\n",
    "    data = pandas.read_csv(data_path, index_col=0)\n",
    "    genes = pandas.read_csv(geneset_list_path, sep='\\t') if geneset_list_path != 'NONE' else None\n",
    "    samples = pandas.read_csv(samples_path, header=None)\n",
    "    labels = pandas.read_csv(labels_path, index_col=0, sep='\\t')\n",
    "    rest_genes = pandas.read_csv(genes_path, header=None)\n",
    "    \n",
    "    output = data.T[rest_genes[0].values]\n",
    "    #data = data / data.sum()\n",
    "    \n",
    "    if genes is not None:\n",
    "        d = dict()\n",
    "        \n",
    "        for i, j in genes.groupby('geneset'):\n",
    "            d[i] = data.loc[j['gene']].sum()\n",
    "            \n",
    "        output = pandas.concat([pandas.DataFrame().from_dict(d), output], axis=1)\n",
    "        \n",
    "    output = output.loc[samples[0].values]\n",
    "    \n",
    "    output.to_csv(sys.argv[6] + '.csv')\n",
    "    labels.loc[samples[0].values].to_csv(sys.argv[6] + '_labels.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN PARAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-22T21:59:59.779417Z",
     "start_time": "2021-04-22T21:58:51.209141Z"
    }
   },
   "outputs": [],
   "source": [
    "PATH_DATA = \"\"\n",
    "PATH_LABELS = \"\"\n",
    "PATH_FULL_DATA = \"\"\n",
    "PATH_SAVE = \"/tmp\"\n",
    "\n",
    "!mkdir -p {PATH_SAVE}/models\n",
    "!mkdir -p {PATH_SAVE}/plots\n",
    "!mkdir -p {PATH_SAVE}/soft_clust\n",
    "\n",
    "command_line_str = \"program.py \" + PATH_DATA + \" \" + PATH_LABELS + \" --full_data \" + PATH_FULL_DATA + \" --save-path \" + PATH_SAVE\n",
    "\n",
    "args = pArgs(command_line_str.split(' '))\n",
    "\n",
    "run_cross(args, rf, 'RandomForestSmall')\n",
    "run_cross(args, rf2, 'RandomForestBig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "notify_time": "5"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
